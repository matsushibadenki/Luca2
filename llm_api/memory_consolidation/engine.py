# /llm_api/memory_consolidation/engine.py
# ã‚¿ã‚¤ãƒˆãƒ«: Memory Consolidation Engine (Final Fix)
# å½¹å‰²: mypyã®ä¸å¯è§£ãªã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚ã€å‡¦ç†ã‚’æ¥µåº¦ã«å˜ç´”åŒ–ã—ã¦è¨˜è¿°ã€‚PCMã§ã¯æ–°è¦æ€§ã‚¹ã‚³ã‚¢ã«åŸºã¥ãçµ±åˆã®å„ªå…ˆåº¦ã‚’æ±ºå®šã™ã‚‹ã€‚

import logging
import asyncio
from typing import Any, Dict, List, Optional, Union

from ..providers.base import LLMProvider
from ..rag.knowledge_base import KnowledgeBase
from . import logic

logger = logging.getLogger(__name__)

class ConsolidationEngine:
    """
    è¨˜æ†¶çµ±åˆã‚¨ãƒ³ã‚¸ãƒ³ã€‚
    çŸ­æœŸçš„ãªå­¦ç¿’çµŒé¨“ã‚’é•·æœŸè¨˜æ†¶ï¼ˆãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ï¼‰ã«çµ±åˆã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç®¡ç†ã™ã‚‹ã€‚
    """

    def __init__(self, provider: LLMProvider, knowledge_graph: Optional[KnowledgeBase] = None):
        self.provider = provider
        # --- â–¼â–¼â–¼ ã“ã“ã‹ã‚‰ä¿®æ­£ â–¼â–¼â–¼ ---
        # å¤‰æ•°åã®ã‚¿ã‚¤ãƒã‚’ä¿®æ­£ (knowledge_base -> knowledge_graph)
        self.knowledge_graph = knowledge_graph or KnowledgeBase()
        # --- â–²â–²â–² ã“ã“ã¾ã§ä¿®æ­£ â–²â–²â–² ---
        self.session_memory_buffer: List[Dict[str, Any]] = []
        # å‹ã‚’æ˜ç¤ºçš„ã« Dict[str, int] ã¨å®šç¾©
        self.consolidation_stats: Dict[str, int] = {
            "total_sessions_processed": 0, "successful_consolidations": 0, "failed_consolidations": 0,
            "total_entities_extracted": 0, "total_relations_extracted": 0
        }
        logger.info("ğŸ§  Memory Consolidation Engine åˆæœŸåŒ–å®Œäº†ã€‚")

    async def consolidate_memories(self, session_data: Union[Dict[str, Any], List[Dict[str, Any]]]) -> Dict[str, Any]:
        """å˜ä¸€ã¾ãŸã¯è¤‡æ•°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨˜æ†¶ã‚’å‡¦ç†ã—ã€é•·æœŸè¨˜æ†¶ã«çµ±åˆã—ã¾ã™ã€‚"""
        sessions = [session_data] if isinstance(session_data, dict) else []
        if isinstance(session_data, list):
            sessions = session_data

        if not sessions:
            return {"status": "skipped", "reason": "No session data"}

        logger.info(f"è¨˜æ†¶çµ±åˆãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹: {len(sessions)}å€‹ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³")
        results: List[Dict[str, Any]] = []
        
        for i, session in enumerate(sessions):
            try:
                # PCMã®ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ï¼šæ–°è¦æ€§ã‚¹ã‚³ã‚¢ãŒé–¾å€¤æœªæº€ã®å ´åˆã€å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
                novelty_score = float(session.get("novelty_score", 0.0))
                if novelty_score < 40.0:
                    logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session.get('session_id', i)} ã®æ–°è¦æ€§ã‚¹ã‚³ã‚¢({novelty_score:.2f})ãŒé–¾å€¤æœªæº€ã®ãŸã‚ã€çµ±åˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                    continue
                logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session.get('session_id', i)} ã®æ–°è¦æ€§ã‚¹ã‚³ã‚¢({novelty_score:.2f})ãŒé–¾å€¤ã‚’è¶…ãˆãŸãŸã‚ã€çµ±åˆã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
                
                current_processed = self.consolidation_stats["total_sessions_processed"]
                self.consolidation_stats["total_sessions_processed"] = current_processed + 1

                structured_info = await logic.analyze_session_data(self.provider, session)
                if not structured_info:
                    current_failed = self.consolidation_stats["failed_consolidations"]
                    self.consolidation_stats["failed_consolidations"] = current_failed + 1
                    continue
                
                update_result = await self._update_knowledge_graph(structured_info)
                
                entities_count = sum(1 for item in structured_info if item.get("type") == "entity")
                relations_count = sum(1 for item in structured_info if item.get("type") == "relation")

                current_entities = self.consolidation_stats["total_entities_extracted"]
                self.consolidation_stats["total_entities_extracted"] = current_entities + entities_count

                current_relations = self.consolidation_stats["total_relations_extracted"]
                self.consolidation_stats["total_relations_extracted"] = current_relations + relations_count
                
                session_id_val = session.get("session_id", "unknown")
                if isinstance(session_id_val, str):
                     pass

                results.append({"session_index": i, "success": True})
                
                current_successful = self.consolidation_stats["successful_consolidations"]
                self.consolidation_stats["successful_consolidations"] = current_successful + 1

            except Exception as e:
                logger.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {i} ã®çµ±åˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                self.consolidation_stats["failed_consolidations"] += 1
                results.append({"session_index": i, "success": False, "error": str(e)})
        
        logger.info("âœ… è¨˜æ†¶çµ±åˆãƒ—ãƒ­ã‚»ã‚¹å®Œäº†ã€‚")
        return {"status": "completed", "results": results, "stats": self.consolidation_stats}

    async def _update_knowledge_graph(self, structured_info: List[Dict[str, Any]]) -> bool:
        """æŠ½å‡ºã•ã‚ŒãŸæƒ…å ±ã‚’ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã«çµ±åˆã—ã¾ã™ã€‚"""
        if not structured_info: return False
        
        knowledge_items = []
        updates_made = False
        for item in structured_info:
            if item.get("confidence", 0.5) < 0.3: continue
            content = logic.format_item_as_knowledge(item)
            if content:
                knowledge_items.append(content)
                updates_made = True
        
        if updates_made:
             logger.info(f"{len(knowledge_items)}å€‹ã®æ–°ã—ã„æƒ…å ±ã‚’çµ±åˆï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰")
        return updates_made
        
    def get_consolidation_statistics(self) -> Dict[str, Any]:
        return self.consolidation_stats

    def add_session_to_buffer(self, session_data: Dict[str, Any]) -> None:
        self.session_memory_buffer.append(session_data)

    async def batch_consolidate_from_buffer(self) -> Dict[str, Any]:
        if not self.session_memory_buffer:
            return {"status": "skipped"}
        sessions_to_process = self.session_memory_buffer.copy()
        self.session_memory_buffer.clear()
        return await self.consolidate_memories(sessions_to_process)