# /llm_api/problem_discovery/discovery_engine.py
# ã‚¿ã‚¤ãƒˆãƒ«: Problem Discovery Engine (Orchestrator)
# å½¹å‰²: å•é¡Œç™ºè¦‹ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å…¨ä½“ã‚’ç®¡ç†ã™ã‚‹ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã€‚ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã€å„ç™ºè¦‹æˆ¦ç•¥ã®å®Ÿè¡Œã€çµæœã®çµ±åˆã¨åˆ†æã‚’èª¿æ•´ã™ã‚‹ã€‚

import asyncio
import json  # â˜… ä¿®æ­£: jsonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import logging
import time
from collections import deque
from typing import Any, Dict, List, Optional, cast

import numpy as np
from ..providers.base import LLMProvider
from .strategies import from_patterns
from . import utils
from .types import DiscoveredProblem # â˜… ä¿®æ­£: å‹å®šç¾©ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

logger = logging.getLogger(__name__)


class ProblemDiscoveryEngine:
    """
    è‡ªå¾‹çš„å•é¡Œç™ºè¦‹ã‚¨ãƒ³ã‚¸ãƒ³ã€‚
    ã‚·ã‚¹ãƒ†ãƒ å†…å¤–ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ã¾ã é¡•åœ¨åŒ–ã—ã¦ã„ãªã„å•é¡Œã‚’ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ç™ºè¦‹ã™ã‚‹ã€‚
    ã“ã®ã‚¯ãƒ©ã‚¹ã¯ã€å‡¦ç†ãƒ•ãƒ­ãƒ¼ã‚’ç®¡ç†ã™ã‚‹ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã€‚
    """

    def __init__(self, provider: LLMProvider):
        """ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–"""
        self.provider = provider
        self.discovered_problems: Dict[str, Any] = {}
        self.discovery_history: deque[Dict[str, Any]] = deque(maxlen=1000)
        logger.info("ğŸ§  Problem Discovery Engine (Orchestrator) åˆæœŸåŒ–å®Œäº†")

    async def discover_problems_from_data(
        self,
        data_sources: List[Dict[str, Any]],
        domain_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ä¸ãˆã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰æ½œåœ¨çš„ãªå•é¡Œã‚’ç™ºè¦‹ã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰ã€‚

        Args:
            data_sources: åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®ãƒªã‚¹ãƒˆã€‚
            domain_context: å•é¡Œç™ºè¦‹ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«é–¢ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã€‚

        Returns:
            ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œã®è¦ç´„ã¨åˆ†æçµæœã‚’å«ã‚€è¾æ›¸ã€‚
        """
        logger.info(f"ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®å•é¡Œç™ºè¦‹ãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹: {len(data_sources)}å€‹ã®ã‚½ãƒ¼ã‚¹")
        domain_context = domain_context or {}
        all_discovered_problems: List[DiscoveredProblem] = []

        # 1. ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
        logger.info("ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’é–‹å§‹...")
        patterns = await utils.extract_data_patterns(self.provider, data_sources)
        anomalies = await utils.detect_anomalies(self.provider, data_sources, patterns)
        causal_networks = await utils.infer_causal_relationships(self.provider, data_sources, patterns)

        # 2. å„ç™ºè¦‹æˆ¦ç•¥ã®ä¸¦åˆ—å®Ÿè¡Œ
        logger.info("ã‚¹ãƒ†ãƒƒãƒ—2: å„ç™ºè¦‹æˆ¦ç•¥ã®ä¸¦åˆ—å®Ÿè¡Œã‚’é–‹å§‹...")
        discovery_tasks = [
            from_patterns.discover_from_patterns(self.provider, patterns, domain_context),
            # ä»–æˆ¦ç•¥ã‚‚åŒæ§˜ã«è¿½åŠ  (ç¾åœ¨ã¯ã‚¹ã‚¿ãƒ–)
            # from_anomalies.discover_from_anomalies(self.provider, anomalies, domain_context),
            # from_causality.discover_from_causality(self.provider, causal_networks, domain_context),
        ]
        results = await asyncio.gather(*discovery_tasks)
        for problems_list in results:
            all_discovered_problems.extend(problems_list)

        # 3. çµæœã®å¾Œå‡¦ç†
        logger.info("ã‚¹ãƒ†ãƒƒãƒ—3: ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œã®å¾Œå‡¦ç†ã‚’é–‹å§‹...")
        unique_problems = utils.deduplicate_and_merge_problems(all_discovered_problems)
        prioritized_problems = utils.prioritize_problems(unique_problems)

        # 4. å•é¡Œã®ç™»éŒ²
        for problem in prioritized_problems:
            if problem.problem_id not in self.discovered_problems:
                self.discovered_problems[problem.problem_id] = problem.to_dict()
                self.discovery_history.append({
                    "timestamp": time.time(),
                    "problem_id": problem.problem_id,
                    "discovery_method": problem.discovery_method.value,
                    "confidence": problem.confidence_score
                })

        # 5. æœ€çµ‚åˆ†æã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        logger.info("ã‚¹ãƒ†ãƒƒãƒ—4: æœ€çµ‚åˆ†æã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’é–‹å§‹...")
        final_analysis = await self._analyze_discovery_results(prioritized_problems)

        discovery_report = {
            "problems_discovered": len(prioritized_problems),
            "problem_details": [utils.format_problem_summary(p) for p in prioritized_problems],
            "discovery_methods_used": list(set(p.discovery_method.value for p in prioritized_problems)),
            "severity_distribution": utils.calculate_severity_distribution(prioritized_problems),
            "high_priority_problems": [p.problem_id for p in prioritized_problems if p.urgency_score > 0.8],
            **final_analysis
        }

        logger.info(f"å•é¡Œç™ºè¦‹å®Œäº†: {len(prioritized_problems)}å€‹ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå•é¡Œã‚’ç™ºè¦‹ãƒ»æ›´æ–°")
        return discovery_report

    async def _analyze_discovery_results(self, problems: List[DiscoveredProblem]) -> Dict[str, Any]:
        """ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œç¾¤å…¨ä½“ã‚’åˆ†æã—ã€é«˜æ¬¡ã®æ´å¯Ÿã‚’å¾—ã‚‹"""
        if not problems:
            return {}

        analysis_prompt = f"""
        ä»¥ä¸‹ã«ã€ã‚·ã‚¹ãƒ†ãƒ å†…ã§è‡ªå¾‹çš„ã«ç™ºè¦‹ã•ã‚ŒãŸæ½œåœ¨çš„ãªå•é¡Œã®ãƒªã‚¹ãƒˆã‚’ç¤ºã—ã¾ã™ã€‚
        ã“ã‚Œã‚‰ã®å•é¡Œå…¨ä½“ã‚’ä¿¯ç°ã—ã€ä»¥ä¸‹ã®ç‚¹ã«ã¤ã„ã¦åˆ†æã—ã¦ãã ã•ã„ã€‚
        1. å…¨ä½“çš„ãªã‚·ã‚¹ãƒ†ãƒ ã®å¥å…¨æ€§ã«é–¢ã™ã‚‹æ´å¯Ÿ
        2. å•é¡Œé–“ã«å…±é€šã™ã‚‹æ ¹æœ¬åŸå› ã‚„ãƒ†ãƒ¼ãƒ
        3. ç‰¹ã«æ³¨æ„ã‚’æ‰•ã†ã¹ãã€è¤‡æ•°ã®å•é¡Œã«ã¾ãŸãŒã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚„é ˜åŸŸ

        ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œãƒªã‚¹ãƒˆ:
        {json.dumps([utils.format_problem_summary(p) for p in problems[:10]], indent=2)}

        åˆ†æçµæœã‚’JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚
        """
        response = await self.provider.call(analysis_prompt, "")
        try:
            analysis = cast(Dict[str, Any], json.loads(response.get("text", "{}")))
            if problems:
                overall_confidence = np.mean([p.confidence_score for p in problems])
                analysis["overall_confidence"] = float(overall_confidence)
            return analysis
        except (json.JSONDecodeError, TypeError):
            return {}