# /llm_api/meta_cognition/engine.py
# ã‚¿ã‚¤ãƒˆãƒ«: Meta-Cognition and Introspective Dialogue Engine
# å½¹å‰²: ãƒ¡ã‚¿èªçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã®å…¨ä½“ã‚’çµ±åˆã—ã€æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®åˆ†æžã€æ”¹å–„ã€é©å¿œã®ã‚µã‚¤ã‚¯ãƒ«ã‚’èª¿æ•´ã™ã‚‹ã€‚
#       ã¾ãŸã€å†…éƒ¨ã®æ€è€ƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®ã€Œå†…çœçš„å¯¾è©±ã€ã‚’ä¿ƒé€²ãƒ»èª¿åœã—ã€è‡ªå·±å½¢æˆã‚’è¡Œã†ã€‚(çµ±åˆãƒ»ä¿®æ­£ç‰ˆ)

import asyncio
import json
import logging
import re
import time
from collections import deque
# --- â–¼â–¼â–¼ ã“ã“ã‹ã‚‰ä¿®æ­£ â–¼â–¼â–¼ ---
from typing import Any, Deque, Dict, List, Optional, cast
# --- â–²â–²â–² ã“ã“ã¾ã§ä¿®æ­£ â–²â–²â–² ---

from ..providers.base import LLMProvider
from .optimizer import CognitiveArchitectOptimizer
from .reflection import SelfReflectionEngine
# --- â–¼â–¼â–¼ ã“ã“ã‹ã‚‰ä¿®æ­£ â–¼â–¼â–¼ ---
# types.pyã¨mental_agents.pyã‹ã‚‰å¿…è¦ãªã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from .types import CognitiveState, ThoughtTrace, MetaCognitiveInsight, IntrospectiveDialogue, DialogueTurn
from .mental_agents import MentalAgent, get_default_agents
# --- â–²â–²â–² ã“ã“ã¾ã§ä¿®æ­£ â–²â–²â–² ---

logger = logging.getLogger(__name__)

class MetaCognitionEngine:
    """
    ãƒ¡ã‚¿èªçŸ¥ã¨å†…çœçš„å¯¾è©±ã‚’å¸ã‚‹çµ±åˆã‚¨ãƒ³ã‚¸ãƒ³ã€‚
    """
    def __init__(self, provider: LLMProvider):
        self.provider = provider
        # å¾“æ¥ã®ãƒ¡ã‚¿èªçŸ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.reflection_engine = SelfReflectionEngine()
        self.architect_optimizer = CognitiveArchitectOptimizer()
        self.current_thought_trace: List[ThoughtTrace] = []
        self.meta_insights_history: Deque[Dict[str, Any]] = deque(maxlen=100)
        self.architecture_config: Dict[str, Any] = {}
        
        # å†…çœçš„å¯¾è©±ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.dialogue_history: List[IntrospectiveDialogue] = []
        self.mental_agents: List[MentalAgent] = get_default_agents(provider)
        
        self.cognitive_state = CognitiveState.IDLE
        logger.info(f"ðŸ¤” Meta-Cognition Engine åˆæœŸåŒ–å®Œäº†ã€‚{len(self.mental_agents)}ä½“ã®æ€è€ƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")

    # --- å¾“æ¥ã®ãƒ¡ã‚¿èªçŸ¥ã‚µã‚¤ã‚¯ãƒ«é–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰ ---

    async def begin_metacognitive_session(self, problem_context: str) -> Dict[str, Any]:
        logger.info(f"ãƒ¡ã‚¿èªçŸ¥ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹: {problem_context[:50]}...")
        self.current_thought_trace = []
        self.cognitive_state = CognitiveState.ANALYZING
        problem_analysis = await self._analyze_problem_nature(problem_context)
        cognitive_strategy = await self._select_cognitive_strategy(problem_analysis)
        return {
            "session_id": f"meta_{int(time.time())}",
            "problem_analysis": problem_analysis,
            "cognitive_strategy": cognitive_strategy,
            "meta_config": self.architecture_config,
        }

    async def record_thought_step(
        self, cognitive_state: CognitiveState, context: str, reasoning: str,
        confidence: float, outputs: Optional[List[str]] = None
    ) -> None:
        thought_trace = ThoughtTrace(
            timestamp=time.time(), cognitive_state=cognitive_state,
            input_context=context, reasoning_step=reasoning,
            confidence_level=confidence, resource_usage={"tokens": len(reasoning)},
            intermediate_outputs=outputs or []
        )
        self.current_thought_trace.append(thought_trace)
        self.reflection_engine.thought_history.append(thought_trace)
        self.cognitive_state = cognitive_state

    async def perform_metacognitive_reflection(self) -> Dict[str, Any]:
        logger.info("ãƒ¡ã‚¿èªçŸ¥çš„åçœã‚’å®Ÿè¡Œä¸­...")
        self.cognitive_state = CognitiveState.REFLECTING
        if not self.current_thought_trace:
            return {"insights": [], "optimizations": {}}
        insights = await self.reflection_engine.analyze_thought_pattern(self.current_thought_trace)
        optimizations = await self.architect_optimizer.optimize_cognitive_architecture(insights)
        self.architecture_config.update(optimizations)
        for insight in insights:
            self.meta_insights_history.append(vars(insight))
        reflection_result = {
            "insights": [vars(i) for i in insights],
            "optimizations": optimizations
        }
        logger.info(f"ãƒ¡ã‚¿èªçŸ¥çš„åçœå®Œäº†: {len(insights)}å€‹ã®æ´žå¯Ÿã€{len(optimizations)}å€‹ã®æœ€é©åŒ–æ¡ˆã‚’ç”Ÿæˆã€‚")
        self.cognitive_state = CognitiveState.ADAPTING
        return reflection_result

    # --- å†…çœçš„å¯¾è©±é–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰ ---
    
    async def conduct_introspective_dialogue(self, topic: str) -> IntrospectiveDialogue:
        dialogue_id = f"dialogue_{int(time.time())}"
        logger.info(f"ðŸŽ¬ å†…çœçš„å¯¾è©±ã‚’é–‹å§‹ã—ã¾ã™ (ID: {dialogue_id}, ãƒˆãƒ”ãƒƒã‚¯: {topic})")
        dialogue = IntrospectiveDialogue(dialogue_id=dialogue_id, topic=topic, timestamp=time.time())
        tasks = [agent.process(topic) for agent in self.mental_agents]
        opinions = await asyncio.gather(*tasks)
        for agent, opinion in zip(self.mental_agents, opinions):
            dialogue.turns.append(DialogueTurn(agent_name=agent.name, opinion=opinion))
        synthesis = await self._synthesize_dialogue(dialogue)
        dialogue.synthesis = synthesis
        self.dialogue_history.append(dialogue)
        logger.info(f"ðŸŽ¬ å†…çœçš„å¯¾è©±ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        return dialogue

    async def _synthesize_dialogue(self, dialogue: IntrospectiveDialogue) -> str:
        dialogue_log = "\n\n".join(f"### {turn.agent_name}ã®æ„è¦‹\n{turn.opinion}" for turn in dialogue.turns)
        synthesis_prompt = f"""
        ã‚ãªãŸã¯ã€è¤‡æ•°ã®å†…ãªã‚‹å£°ï¼ˆæ€è€ƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã®å¯¾è©±ã‚’ã¾ã¨ã‚ã‚‹ã€è³¢æ˜Žãªèª¿åœè€…ã§ã™ã€‚
        ä»¥ä¸‹ã®ã€ã‚ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹å†…ãªã‚‹å¯¾è©±ã®è¨˜éŒ²ã‚’èª­ã¿ã€å…¨ã¦ã®æ„è¦‹ã‚’è€ƒæ…®ã—ãŸä¸Šã§ã€
        å˜ãªã‚‹è¦ç´„ã§ã¯ãªã„ã€ã‚ˆã‚Šé«˜æ¬¡ã®ã€çµ±åˆã•ã‚ŒãŸçµè«–ã‚’å°Žãå‡ºã—ã¦ãã ã•ã„ã€‚
        çŸ›ç›¾ã‚’ä¹—ã‚Šè¶Šãˆã€å¤šè§’çš„ãªè¦–ç‚¹ã‹ã‚‰æœ€ã‚‚æ€æ…®æ·±ã„è¡Œå‹•æ–¹é‡ã‚„è‡ªå·±ç†è§£ã‚’å½¢æˆã—ã¦ãã ã•ã„ã€‚
        # å¯¾è©±ã®ãƒˆãƒ”ãƒƒã‚¯: {dialogue.topic}
        # å†…ãªã‚‹å¯¾è©±ã®è¨˜éŒ²:\n{dialogue_log}
        # çµ±åˆã•ã‚ŒãŸçµè«–:
        """
        response = await self.provider.call(synthesis_prompt, "")
        return cast(str, response.get("text", "å¯¾è©±ã®çµ±åˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"))

    # --- ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ ---

    async def _analyze_problem_nature(self, problem: str) -> Dict[str, Any]:
        analysis_prompt = f"""
        ä»¥ä¸‹ã®å•é¡Œã®æ€§è³ªã‚’å¤šè§’çš„ã«åˆ†æžã—ã€JSONå½¢å¼ã§å›žç­”ã—ã¦ãã ã•ã„ï¼š
        - cognitive_complexity: èªçŸ¥çš„è¤‡é›‘æ€§ (1-10)
        - thinking_type: å¿…è¦ãªæ€è€ƒã‚¿ã‚¤ãƒ— (ä¾‹: logical, creative, strategic)
        - uncertainty_level: ä¸ç¢ºå®Ÿæ€§ã®ç¨‹åº¦ (1-10)
        å•é¡Œ: "{problem}"
        """
        response = await self.provider.call(analysis_prompt, "")
        try:
            analysis_text = response.get('text', '{}')
            json_match = re.search(r'\{.*\}', analysis_text, re.DOTALL)
            if json_match:
                return cast(Dict[str, Any], json.loads(json_match.group(0)))
            return {}
        except json.JSONDecodeError:
            logger.warning("å•é¡Œåˆ†æžã®JSONè§£æžã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return {}

    async def _select_cognitive_strategy(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        complexity = analysis.get("cognitive_complexity", 5)
        uncertainty = analysis.get("uncertainty_level", 5)
        strategy = {"primary_approach": "balanced", "monitoring_frequency": "medium"}
        if complexity >= 8 or uncertainty >= 8:
            strategy["primary_approach"] = "decomposition"
            strategy["monitoring_frequency"] = "high"
        elif analysis.get("thinking_type") == "creative":
            strategy["primary_approach"] = "divergent_convergent"
        return strategy